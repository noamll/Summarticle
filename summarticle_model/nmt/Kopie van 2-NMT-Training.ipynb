{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16565,
     "status": "ok",
     "timestamp": 1696329933026,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "vSUyCs23M_H2",
    "outputId": "d152cd9e-ca0b-4b15-db49-0060a43163c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting OpenNMT-py\n",
      "  Downloading OpenNMT_py-3.4.1-py3-none-any.whl (252 kB)\n",
      "     -------------------------------------- 252.9/252.9 kB 7.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from OpenNMT-py) (6.0)\n",
      "Requirement already satisfied: six in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from OpenNMT-py) (1.16.0)\n",
      "Requirement already satisfied: torch<2.1,>=2.0 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from OpenNMT-py) (2.0.1)\n",
      "Collecting ctranslate2<4,>=3.2\n",
      "  Downloading ctranslate2-3.20.0-cp39-cp39-win_amd64.whl (20.2 MB)\n",
      "     --------------------------------------- 20.2/20.2 MB 18.2 MB/s eta 0:00:00\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.7.0-cp39-cp39-win_amd64.whl (12.1 MB)\n",
      "     --------------------------------------- 12.1/12.1 MB 15.6 MB/s eta 0:00:00\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "     ---------------------------------------- 118.9/118.9 kB ? eta 0:00:00\n",
      "Collecting fasttext-wheel\n",
      "  Downloading fasttext_wheel-0.9.2-cp39-cp39-win_amd64.whl (225 kB)\n",
      "     ------------------------------------- 225.6/225.6 kB 13.5 MB/s eta 0:00:00\n",
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.3.1-cp39-cp39-win_amd64.whl (1.8 MB)\n",
      "     ---------------------------------------- 1.8/1.8 MB 16.5 MB/s eta 0:00:00\n",
      "Collecting waitress\n",
      "  Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.7/57.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: flask in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from OpenNMT-py) (1.1.2)\n",
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-2.0.0-cp39-cp39-win_amd64.whl (39 kB)\n",
      "Collecting pyonmttok<2,>=1.35\n",
      "  Downloading pyonmttok-1.37.1-cp39-cp39-win_amd64.whl (14.4 MB)\n",
      "     ---------------------------------------- 14.4/14.4 MB 7.3 MB/s eta 0:00:00\n",
      "Collecting tensorboard>=2.3\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 18.5 MB/s eta 0:00:00\n",
      "Collecting configargparse\n",
      "  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from ctranslate2<4,>=3.2->OpenNMT-py) (1.21.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from tensorboard>=2.3->OpenNMT-py) (3.3.4)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "     ---------------------------------------- 130.2/130.2 kB ? eta 0:00:00\n",
      "Collecting protobuf>=3.19.6\n",
      "  Downloading protobuf-4.24.3-cp39-cp39-win_amd64.whl (430 kB)\n",
      "     ------------------------------------- 430.5/430.5 kB 26.3 MB/s eta 0:00:00\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.23.2-py2.py3-none-any.whl (181 kB)\n",
      "     ------------------------------------- 182.0/182.0 kB 11.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from tensorboard>=2.3->OpenNMT-py) (2.28.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from tensorboard>=2.3->OpenNMT-py) (63.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from tensorboard>=2.3->OpenNMT-py) (2.0.3)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.59.0-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "     ---------------------------------------- 3.7/3.7 MB 21.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from torch<2.1,>=2.0->OpenNMT-py) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from torch<2.1,>=2.0->OpenNMT-py) (4.3.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from torch<2.1,>=2.0->OpenNMT-py) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from torch<2.1,>=2.0->OpenNMT-py) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from torch<2.1,>=2.0->OpenNMT-py) (2.11.3)\n",
      "Collecting pybind11>=2.2\n",
      "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
      "     ---------------------------------------- 227.7/227.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from flask->OpenNMT-py) (2.0.1)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from flask->OpenNMT-py) (8.0.4)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from sacrebleu->OpenNMT-py) (0.8.10)\n",
      "Requirement already satisfied: lxml in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from sacrebleu->OpenNMT-py) (4.9.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from sacrebleu->OpenNMT-py) (0.4.5)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: regex in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from sacrebleu->OpenNMT-py) (2022.7.9)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from spacy->OpenNMT-py) (5.2.1)\n",
      "Collecting thinc<8.3.0,>=8.1.8\n",
      "  Downloading thinc-8.2.1-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 23.5 MB/s eta 0:00:00\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     ------------------------------------- 181.6/181.6 kB 10.7 MB/s eta 0:00:00\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "     ------------------------------------- 395.8/395.8 kB 24.1 MB/s eta 0:00:00\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.8-cp39-cp39-win_amd64.whl (483 kB)\n",
      "     ------------------------------------- 483.8/483.8 kB 10.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from spacy->OpenNMT-py) (4.64.1)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.10-cp39-cp39-win_amd64.whl (25 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.9-cp39-cp39-win_amd64.whl (122 kB)\n",
      "     -------------------------------------- 122.7/122.7 kB 7.5 MB/s eta 0:00:00\n",
      "Collecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.2-py3-none-any.whl (48 kB)\n",
      "     ---------------------------------------- 48.9/48.9 kB ? eta 0:00:00\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 45.9/45.9 kB ? eta 0:00:00\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.8-cp39-cp39-win_amd64.whl (39 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0\n",
      "  Downloading weasel-0.3.1-py3-none-any.whl (50 kB)\n",
      "     ---------------------------------------- 50.0/50.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from spacy->OpenNMT-py) (21.3)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.2.8)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from jinja2->torch<2.1,>=2.0->OpenNMT-py) (2.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy->OpenNMT-py) (3.0.9)\n",
      "Collecting pydantic-core==2.10.1\n",
      "  Downloading pydantic_core-2.10.1-cp39-none-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 21.0 MB/s eta 0:00:00\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2022.9.14)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.11-cp39-cp39-win_amd64.whl (6.6 MB)\n",
      "     ---------------------------------------- 6.6/6.6 MB 13.7 MB/s eta 0:00:00\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.3-py3-none-any.whl (34 kB)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting cloudpathlib<0.16.0,>=0.7.0\n",
      "  Downloading cloudpathlib-0.15.1-py3-none-any.whl (43 kB)\n",
      "     ---------------------------------------- 43.9/43.9 kB ? eta 0:00:00\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from portalocker->sacrebleu->OpenNMT-py) (302)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from sympy->torch<2.1,>=2.0->OpenNMT-py) (1.2.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\jklus\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 9.4 MB/s eta 0:00:00\n",
      "Installing collected packages: cymem, waitress, typing-extensions, tensorboard-data-server, spacy-loggers, spacy-legacy, rsa, rapidfuzz, pyonmttok, pybind11, pyahocorasick, protobuf, portalocker, oauthlib, murmurhash, langcodes, grpcio, ctranslate2, configargparse, colorama, catalogue, cachetools, blis, annotated-types, absl-py, wasabi, srsly, sacrebleu, requests-oauthlib, pydantic-core, preshed, google-auth, fasttext-wheel, cloudpathlib, typer, pydantic, google-auth-oauthlib, tensorboard, pathy, confection, weasel, thinc, spacy, OpenNMT-py\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.5\n",
      "    Uninstalling colorama-0.4.5:\n",
      "      Successfully uninstalled colorama-0.4.5\n",
      "Successfully installed OpenNMT-py-3.4.1 absl-py-2.0.0 annotated-types-0.5.0 blis-0.7.11 cachetools-5.3.1 catalogue-2.0.10 cloudpathlib-0.15.1 colorama-0.4.6 confection-0.1.3 configargparse-1.7 ctranslate2-3.20.0 cymem-2.0.8 fasttext-wheel-0.9.2 google-auth-2.23.2 google-auth-oauthlib-1.0.0 grpcio-1.59.0 langcodes-3.3.0 murmurhash-1.0.10 oauthlib-3.2.2 pathy-0.10.2 portalocker-2.8.2 preshed-3.0.9 protobuf-4.24.3 pyahocorasick-2.0.0 pybind11-2.11.1 pydantic-2.4.2 pydantic-core-2.10.1 pyonmttok-1.37.1 rapidfuzz-3.3.1 requests-oauthlib-1.3.1 rsa-4.9 sacrebleu-2.3.1 spacy-3.7.0 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 tensorboard-2.14.1 tensorboard-data-server-0.7.1 thinc-8.2.1 typer-0.7.0 typing-extensions-4.8.0 waitress-2.1.2 wasabi-1.1.2 weasel-0.3.1\n"
     ]
    }
   ],
   "source": [
    "# Install OpenNMT-py 3.x\n",
    "!pip3 install OpenNMT-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhgIdJn-cLqu"
   },
   "source": [
    "# Prepare Your Datasets\n",
    "Please make sure you have completed the [first exercise](https://colab.research.google.com/drive/1rsFPnAQu9-_A6e2Aw9JYK3C8mXx9djsF?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1696329933026,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "dWVOWYedzZ_G",
    "outputId": "0e27ac2b-f1a9-4b20-c98a-d6675a783dee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] Het systeem kan het opgegeven pad niet vinden: '/content/drive/MyDrive/nmt/'\n",
      "C:\\Users\\jklus\\Desktop\\Mappen\\School\\TiU\\2023-2024 jaar3\\Software Engineering for CSAI\\Opdrachten\\Model\\nmt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Open the folder where you saved your prepapred datasets from the first exercise\n",
    "# You might need to mount your Google Drive first\n",
    "%cd /content/drive/MyDrive/nmt/\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 14010,
     "status": "error",
     "timestamp": 1696329947031,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "UF2PU_YnNSN-",
    "outputId": "6895bc44-4803-4374-f3b2-1cefa110f940"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19316\\1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPlmhd426B7l"
   },
   "source": [
    "# Create the Training Configuration File\n",
    "\n",
    "The following config file matches most of the recommended values for the Transformer model [Vaswani et al., 2017](https://arxiv.org/abs/1706.03762). As the current dataset is small, we reduced the following values:\n",
    "* `train_steps` - for datasets with a few millions of sentences, consider using a value between 100000 and 200000, or more! Enabling the option `early_stopping` can help stop the training when there is no considerable improvement.\n",
    "* `valid_steps` - 10000 can be good if the value `train_steps` is big enough.\n",
    "* `warmup_steps` - obviously, its value must be less than `train_steps`. Try 4000 and 8000 values.\n",
    "\n",
    "Refer to [OpenNMT-py training parameters](https://opennmt.net/OpenNMT-py/options/train.html) for more details. If you are interested in further explanation of the Transformer model, you can check this article, [Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947031,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "qbW7Xek6UDlY"
   },
   "outputs": [],
   "source": [
    "# Create the YAML configuration file\n",
    "# On a regular machine, you can create it manually or with nano\n",
    "# Note here we are using some smaller values because the dataset is small\n",
    "# For larger datasets, consider increasing: train_steps, valid_steps, warmup_steps, save_checkpoint_steps, keep_checkpoint\n",
    "\n",
    "config = '''# config.yaml\n",
    "\n",
    "\n",
    "## Where the samples will be written\n",
    "save_data: run\n",
    "\n",
    "# Training files\n",
    "data:\n",
    "    corpus_1:\n",
    "        path_src: WikiMatrix.en-nl.en-filtered.en.subword.train\n",
    "        path_tgt: WikiMatrix.en-nl.nl-filtered.nl.subword.train\n",
    "        transforms: [filtertoolong]\n",
    "    valid:\n",
    "        path_src: WikiMatrix.en-nl.en-filtered.en.subword.dev\n",
    "        path_tgt: WikiMatrix.en-nl.nl-filtered.nl.subword.dev\n",
    "        transforms: [filtertoolong]\n",
    "\n",
    "# Vocabulary files, generated by onmt_build_vocab\n",
    "src_vocab: run/source.vocab\n",
    "tgt_vocab: run/target.vocab\n",
    "\n",
    "# Vocabulary size - should be the same as in sentence piece\n",
    "src_vocab_size: 50000\n",
    "tgt_vocab_size: 50000\n",
    "\n",
    "# Filter out source/target longer than n if [filtertoolong] enabled\n",
    "src_seq_length: 150\n",
    "src_seq_length: 150\n",
    "\n",
    "# Tokenization options\n",
    "src_subword_model: source.model\n",
    "tgt_subword_model: target.model\n",
    "\n",
    "# Where to save the log file and the output models/checkpoints\n",
    "log_file: train.log\n",
    "save_model: models/model.fren\n",
    "\n",
    "# Stop training if it does not imporve after n validations\n",
    "early_stopping: 4\n",
    "\n",
    "# Default: 5000 - Save a model checkpoint for each n\n",
    "save_checkpoint_steps: 1000\n",
    "\n",
    "# To save space, limit checkpoints to last n\n",
    "# keep_checkpoint: 3\n",
    "\n",
    "seed: 3435\n",
    "\n",
    "# Default: 100000 - Train the model to max n steps\n",
    "# Increase to 200000 or more for large datasets\n",
    "# For fine-tuning, add up the required steps to the original steps\n",
    "train_steps: 3000\n",
    "\n",
    "# Default: 10000 - Run validation after n steps\n",
    "valid_steps: 1000\n",
    "\n",
    "# Default: 4000 - for large datasets, try up to 8000\n",
    "warmup_steps: 1000\n",
    "report_every: 100\n",
    "\n",
    "# Number of GPUs, and IDs of GPUs\n",
    "world_size: 1\n",
    "gpu_ranks: [0]\n",
    "\n",
    "# Batching\n",
    "bucket_size: 262144\n",
    "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
    "batch_type: \"tokens\"\n",
    "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
    "valid_batch_size: 2048\n",
    "max_generator_batches: 2\n",
    "accum_count: [4]\n",
    "accum_steps: [0]\n",
    "\n",
    "# Optimization\n",
    "model_dtype: \"fp16\"\n",
    "optim: \"adam\"\n",
    "learning_rate: 2\n",
    "# warmup_steps: 8000\n",
    "decay_method: \"noam\"\n",
    "adam_beta2: 0.998\n",
    "max_grad_norm: 0\n",
    "label_smoothing: 0.1\n",
    "param_init: 0\n",
    "param_init_glorot: true\n",
    "normalization: \"tokens\"\n",
    "\n",
    "# Model\n",
    "encoder_type: transformer\n",
    "decoder_type: transformer\n",
    "position_encoding: true\n",
    "enc_layers: 6\n",
    "dec_layers: 6\n",
    "heads: 8\n",
    "hidden_size: 512\n",
    "word_vec_size: 512\n",
    "transformer_ff: 2048\n",
    "dropout_steps: [0]\n",
    "dropout: [0.1]\n",
    "attention_dropout: [0.1]\n",
    "'''\n",
    "\n",
    "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
    "  config_yaml.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947031,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "vsL4zycvLMUx"
   },
   "outputs": [],
   "source": [
    "# [Optional] Check the content of the configuration file\n",
    "!cat config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0bcqYkEXhRY"
   },
   "source": [
    "# Build Vocabulary\n",
    "\n",
    "For large datasets, it is not feasable to use all words/tokens found in the corpus. Instead, a specific set of vocabulary is extracted from the training dataset, usually betweeen 32k and 100k words. This is the main purpose of the vocabulary building step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947031,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "AuwltKp_VhnQ"
   },
   "outputs": [],
   "source": [
    "# Find the number of CPUs/cores on the machine\n",
    "!nproc --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1696329947032,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "P2GV1PgyUsJr"
   },
   "outputs": [],
   "source": [
    "# Build Vocabulary\n",
    "\n",
    "# -config: path to your config.yaml file\n",
    "# -n_sample: use -1 to build vocabulary on all the segment in the training dataset\n",
    "# -num_threads: change it to match the number of CPUs to run it faster\n",
    "\n",
    "!onmt_build_vocab -config config.yaml -n_sample -1 -num_threads 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncWyNtxiO_Ov"
   },
   "source": [
    "From the **Runtime menu** > **Change runtime type**, make sure that the \"**Hardware accelerator**\" is \"**GPU**\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947032,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "TMMPeS-pSV8I"
   },
   "outputs": [],
   "source": [
    "# Check if the GPU is active\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947032,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "_3rVQhd4NXNG"
   },
   "outputs": [],
   "source": [
    "# Check if the GPU is visable to PyTorch\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "gpu_memory = torch.cuda.mem_get_info(0)\n",
    "print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aCxETSnXcL-"
   },
   "source": [
    "# Training\n",
    "\n",
    "Now, start training your NMT model! ðŸŽ‰ ðŸŽ‰ ðŸŽ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947032,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "HZd1o1kIb6Nv"
   },
   "outputs": [],
   "source": [
    "!rm -rf drive/MyDrive/nmt/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947032,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "prJCKA2CP-dl"
   },
   "outputs": [],
   "source": [
    "# Train the NMT model\n",
    "!onmt_train -config config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947032,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "XUYAvE8ffK2k"
   },
   "outputs": [],
   "source": [
    "# For error debugging try:\n",
    "# !dmesg -T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eShpS01j-Jcp"
   },
   "source": [
    "# Translation\n",
    "\n",
    "Translation Options:\n",
    "* `-model` - specify the last model checkpoint name; try testing the quality of multiple checkpoints\n",
    "* `-src` - the subworded test dataset, source file\n",
    "* `-output` - give any file name to the new translation output file\n",
    "* `-gpu` - GPU ID, usually 0 if you have one GPU. Otherwise, it will translate on CPU, which would be slower.\n",
    "* `-min_length` - [optional] to avoid empty translations\n",
    "* `-verbose` - [optional] if you want to print translations\n",
    "\n",
    "Refer to [OpenNMT-py translation options](https://opennmt.net/OpenNMT-py/options/translate.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947032,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "MbQEGTj4TybH"
   },
   "outputs": [],
   "source": [
    "# Translate the \"subworded\" source file of the test dataset\n",
    "# Change the model name, if needed.\n",
    "!onmt_translate -model models/model.fren_step_3000.pt -src WikiMatrix.en-nl.en.subword.test -output WikiMatrix.nl.translated -gpu 0 -min_length 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947032,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "XHYihrgfIrIO"
   },
   "outputs": [],
   "source": [
    "# Check the first 5 lines of the translation file\n",
    "!head -n 5 WikiMatrix.nl.translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947033,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "zRsJm6UET2C_"
   },
   "outputs": [],
   "source": [
    "# If needed install/update sentencepiece\n",
    "!pip3 install --upgrade -q sentencepiece\n",
    "\n",
    "# Desubword the translation file\n",
    "!python3 MT-Preparation/subwording/3-desubword.py target.model WikiMatrix.nl.translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947033,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "ai4RhhGaKBp1"
   },
   "outputs": [],
   "source": [
    "# Check the first 5 lines of the desubworded translation file\n",
    "!head -n 5 WikiMatrix.nl.translated.desubword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947033,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "kOUWB4r3OFOV"
   },
   "outputs": [],
   "source": [
    "# Desubword the target file (reference) of the test dataset\n",
    "# Note: You might as well have split files *before* subwording during dataset preperation,\n",
    "# but sometimes datasets have tokeniztion issues, so this way you are sure the file is really untokenized.\n",
    "!python3 MT-Preparation/subwording/3-desubword.py target.model WikiMatrix.en-nl.nl.subword.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947033,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "0jULN0MwOFeH"
   },
   "outputs": [],
   "source": [
    "# Check the first 5 lines of the desubworded reference\n",
    "!head -n 5 WikiMatrix.en-nl.nl.subword.test.desubword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHMumxqvLDDc"
   },
   "source": [
    "# MT Evaluation\n",
    "\n",
    "There are several MT Evaluation metrics such as BLEU, TER, METEOR, COMET, BERTScore, among others.\n",
    "\n",
    "Here we are using BLEU. Files must be detokenized/desubworded beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947033,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "w-9XGYnaJ-Nj"
   },
   "outputs": [],
   "source": [
    "# Download the BLEU script\n",
    "!wget https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947033,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "rYDG0x0KLk_O"
   },
   "outputs": [],
   "source": [
    "# Install sacrebleu\n",
    "!pip3 install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1696329947033,
     "user": {
      "displayName": "Jeroen Kluskens",
      "userId": "03009847662037463989"
     },
     "user_tz": -120
    },
    "id": "W3V3tZphTzK9"
   },
   "outputs": [],
   "source": [
    "# Evaluate the translation (without subwording)\n",
    "!python3 compute-bleu.py WikiMatrix.en-nl.nl.subword.test.desubword WikiMatrix.nl.translated.desubword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBi1PhRv4bX9"
   },
   "source": [
    "# More Features and Directions to Explore\n",
    "\n",
    "Experiment with the following ideas:\n",
    "* Icrease `train_steps` and see to what extent new checkpoints provide better translation, in terms of both BLEU and your human evaluation.\n",
    "\n",
    "* Check other MT Evaluation mentrics other than BLEU such as [TER](https://github.com/mjpost/sacrebleu#ter), [WER](https://blog.machinetranslation.io/compute-wer-score/), [METEOR](https://blog.machinetranslation.io/compute-bleu-score/#meteor), [COMET](https://github.com/Unbabel/COMET), and [BERTScore](https://github.com/Tiiiger/bert_score). What are the conceptual differences between them? Is there special cases for using a specific metric?\n",
    "\n",
    "* Continue training from the last model checkpoint using the `-train_from` option, only if the training stopped and you want to continue it. In this case, `train_steps` in the config file should be larger than the steps of the last checkpoint you train from.\n",
    "```\n",
    "!onmt_train -config config.yaml -train_from models/model.fren_step_3000.pt\n",
    "```\n",
    "\n",
    "* **Ensemble Decoding:** During translation, instead of adding one model/checkpoint to the `-model` argument, add multiple checkpoints. For example, try the two last checkpoints. Does it improve quality of translation? Does it affect translation seepd?\n",
    "\n",
    "* **Averaging Models:** Try to average multiple models into one model using the [average_models.py](https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/bin/average_models.py) script, and see how this affects translation quality.\n",
    "```\n",
    "python3 average_models.py -models model_step_xxx.pt model_step_yyy.pt -output model_avg.pt\n",
    "```\n",
    "* **Release the model:** Try this command and see how it reduce the model size.\n",
    "```\n",
    "onmt_release_model --model \"model.pt\" --output \"model_released.pt\n",
    "```\n",
    "* **Use CTranslate2:** For efficient translation, consider using [CTranslate2](https://github.com/OpenNMT/CTranslate2), a fast inference engine. Check out an [example](https://gist.github.com/ymoslem/60e1d1dc44fe006f67e130b6ad703c4b).\n",
    "\n",
    "* **Work on low-resource languages:** Find out more details about [how to train NMT models for low-resource languages](https://blog.machinetranslation.io/low-resource-nmt/).\n",
    "\n",
    "* **Train a multilingual model:** Find out helpful notes about [training multilingual models](https://blog.machinetranslation.io/multilingual-nmt).\n",
    "\n",
    "* **Publish a demo:** Show off your work through a [simple demo with CTranslate2 and Streamlit](https://blog.machinetranslation.io/nmt-web-interface/).\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/ymoslem/OpenNMT-Tutorial/blob/main/2-NMT-Training.ipynb",
     "timestamp": 1696321740724
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
