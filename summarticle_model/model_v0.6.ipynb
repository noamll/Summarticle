{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from pypdf.errors import PdfReadError\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sentencepiece\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt') # only uncomment if not already downloaded\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6303f79-458a-46b0-94af-820a3a4d65c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ArticleToSummarize = \"pdf_database\\pdf4.pdf\"\n",
    "\n",
    "def pdfTE(pdfFile, version=1, start=0, end=0): # Function for text extraction from PDF. # Version states which version to use, with arguments(start, end) being the starting page and ending page.\n",
    "    if version==1:\n",
    "        with open(pdfFile, \"rb\") as file: # Read in binary to handle breakline statements better (\\n)\n",
    "            pdfReader = PdfReader(file)\n",
    "            for page in pdfReader.pages:\n",
    "                yield page.extract_text() # Use of generator as keeping the whole article in the memory results in memory error.\n",
    "    else:\n",
    "        with open(pdfFile, \"rb\") as file: # Read in binary to handle breakline statements better (\\n)\n",
    "            pdfReader = PdfReader(file)\n",
    "            if end==0:\n",
    "                end=len(pdfReader.pages)-1\n",
    "            for num in range(start,end): # Iterator over page (num) \n",
    "                yield pdfReader.pages[num].extract_text() # Text extraction of page (num)\n",
    "            \n",
    "def articleC(pdfFile, version=1,start=0,end=0): # Function to return the article in one string # Version and start, end arguments necessary for pdfTE integration.\n",
    "    if version==1:\n",
    "        textCombiner = pdfTE(pdfFile)\n",
    "    else:\n",
    "        textCombiner = pdfTE(pdfFile,2,start,end) # Choosing for version 2 if sumArticle2 failed on version 1\n",
    "    textCombined = \"\"\n",
    "    for text in textCombiner: # Loop over generator object to sum text of pages into one string\n",
    "        textCombined += text\n",
    "    if textCombined == \"\":\n",
    "        raise Exception(\"Oops! The task failed as the PDF file is empty.\") # Exception that handles empty files\n",
    "    elif len(textCombined) < 10:\n",
    "        raise Exception(\"Oops! The task failed as the PDF file has too little characters.\") # Exception that handles files with too little characters for a summary\n",
    "    else:\n",
    "        return textCombined\n",
    "\n",
    "def sumArticle2(pdfFile): # Function to summarize article as a whole\n",
    "    if pdfFile.endswith(\".pdf\"): # First check if file extension is \".pdf\" format.\n",
    "        try:\n",
    "            summarizer = pipeline(\"summarization\", model=\"pszemraj/led-large-book-summary\") # Model used from the huggingface hub (https://huggingface.co/pszemraj/led-large-book-summary)\n",
    "            articleCombined = articleC(pdfFile) # Iterate over text combiner function\n",
    "            summarizedPage = summarizer(articleCombined,max_length=1000, min_length=200, do_sample=True) # Max/min length for length of summarization in characters.\n",
    "            return summarizedPage[0][\"summary_text\"] # Return summary as string\n",
    "        except PdfReadError as PRE: # Second check if file extension is \".pdf\" format when first check fails.\n",
    "            return f\"Oops! a PDF Read Error {PRE} happened. Please retry the task once the issue has been resolved.\"\n",
    "        except OSError as OS: # Exception handling of OS errors, as PdfReadError doesn't catch all file extension errors.\n",
    "            return f\"Oops! an OS Error {OS} happened. Please retry the task once the issue has been resolved.\"\n",
    "        except (RuntimeError, IndexError) as RIE: # Exception check if pdf fails to be summarized due to it having too many tokens (> 16384)\n",
    "            print(f\"Oops! {RIE}, The file was too big to configure.\")\n",
    "            try:\n",
    "                amountPages = int(input(\"Per how many pages would you like a summary? \")) # Asking user input to make the summary/ies on.\n",
    "                print(\"Warning, this summary may take a while to produce.\\n\") # Give feedback to the user that because of the large pdf, the models computation will be larger\n",
    "                if amountPages == 1: # If the user wants to get a summary per page, the calculation of the articleC function needs to be changed.\n",
    "                    end = amountPages\n",
    "                else:\n",
    "                    end = amountPages-1 # If the user wants to get a summary per an amount of pages, the calculation needs to be the standard one.\n",
    "                start = 0\n",
    "                summary = \"\" # Empty string to merge all the separate summaries in\n",
    "                length = len(PdfReader(ArticleToSummarize).pages) # Amount of pages in article\n",
    "                lastRun = False\n",
    "                while True: # Loop till all the pages have been summarized\n",
    "                    articleCombined = articleC(pdfFile,2,start,end)\n",
    "                    if amountPages == 1:\n",
    "                        summarizedPage = summarizer(articleCombined,max_length=200, min_length=50, do_sample=False) # Summarizer for per page, different max/min length as per page has less characters in one iteration than per amount of pages, gives warning if min/max is too little.\n",
    "                        summary += f\"Summary of page {start+1}:\\n \\n{summarizedPage[0]['summary_text']}\\n\\n\" + \"-=-\" + \"\\n\"\n",
    "                    else:\n",
    "                        summarizedPage = summarizer(articleCombined,max_length=1000, min_length=200, do_sample=False) # Max/min length for length of summarization  per amount of pages in characters.\n",
    "                        summary += f\"Summary of pages {start+1}-{end+1}:\\n \\n{summarizedPage[0]['summary_text']}\\n\\n\" + \"-=-\" + \"\\n\"   \n",
    "                    start += amountPages # Calculations to determine next start/end point of iteration.\n",
    "                    end += amountPages\n",
    "                    if lastRun | start>=length: # Checker if program needs to stop executing\n",
    "                        break\n",
    "                    if amountPages == 1: # Once summarizer reaches last page in per-page summarization, it tells program to stop after one last run\n",
    "                        if end == length-1:\n",
    "                            lastRun = True\n",
    "                    if end>length | end==length: # Once summarizer reaches last page in summarization, it tells program to stop after one last run\n",
    "                        end=length-1\n",
    "                        lastRun = True\n",
    "                summaryF = summarizer(summary,max_length=2000, min_length=200, do_sample=False)        \n",
    "                return summaryF[0]['summary_text']\n",
    "            except ValueError as VE: # Exception that handles user input.\n",
    "                return f\"Oops! {VE}, You didn't give an integer.\"\n",
    "            except IndexError as IE: # Exception that handles user input.\n",
    "                return f\"Oops! {IE}, you gave an integer larger than the actual amount of pages in the paper.\"\n",
    "            except Exception as E: # Exception that handles all different errors and asks user to feedback the error to the devs to enhance the model.\n",
    "                return f\"Oops! An unexpected error occured, {E}. Please report the error to the team.\"\n",
    "    else:\n",
    "        raise Exception(\"The file format is not a valid pdf.\")\n",
    "\n",
    "def pdfKE(pdfFile, language='english'): # Function to extract keywords from the PDF, language input needed as language needs to be part of stopwords folder. Standard keyword is english\n",
    "    if pdfFile.endswith(\".pdf\"): # First check if file extension is \".pdf\" format.\n",
    "        try:\n",
    "            articleCombined = articleC(pdfFile).lower() # Iterate over generator\n",
    "            tokens = word_tokenize(articleCombined) # Tokenize all words in the article\n",
    "            punctuations = [\"(\",\")\",\";\",\":\",\"[\",\"]\",\",\",\"!\",\"=\",\"==\",\"<\",\">\",\"@\",\"#\",\"$\",\"%\",\"^\",\"&\",\"*\",\".\",\"//\",\"{\",\"}\",\"...\",\"``\",\"+\",\"\\'\\'\",\"-\",\"~\",\"\\\"\",\"’\",]\n",
    "            stopWords = stopwords.words(f'{language}')\n",
    "            keywords = [word for word in tokens if word not in stopWords and word not in punctuations] # Filter the words so that mostlikely keywords will be extracted\n",
    "            keywordExtracted = pd.Series(keywords).value_counts().index[:5] # Keywords formatting as a list\n",
    "            keywordString = \" \".join(keywordExtracted) # Keywords formatting as a string\n",
    "            keywordDict = {i+1:keywordExtracted[i] for i in range(5)}\n",
    "            return keywordDict\n",
    "        except PdfReadError as PRE: # Second check if file extension is \".pdf\" format when first check fails.\n",
    "            return f\"Oops! a PDF Read Error {PRE} happened. Please retry the task once the issue has been resolved.\"\n",
    "        except OSError as OS: # Exception handling of OS errors, as PdfReadError doesn't catch all file extension errors.\n",
    "            return f\"Oops! an OS Error {OS} happened. Please retry the task once the issue has been resolved.\"\n",
    "        except Exception as E: # Exception that handles all different errors and asks user to feedback the error to the devs to enhance the model.\n",
    "            return f\"Oops! An unexpected error occured, {E}. Please report the error to the team.\"\n",
    "    else:\n",
    "        raise Exception(\"The file format is not a valid pdf.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Oops! The task failed as the PDF file is empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14584\\4200367548.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Summarize text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msumArticle2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mArticleToSummarize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14584\\2328961048.py\u001b[0m in \u001b[0;36msumArticle2\u001b[1;34m(pdfFile)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0msummarizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"summarization\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pszemraj/led-large-book-summary\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Model used from the huggingface hub (https://huggingface.co/pszemraj/led-large-book-summary)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0marticleCombined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marticleC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdfFile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Iterate over text combiner function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0msummarizedPage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticleCombined\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Max/min length for length of summarization in characters.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msummarizedPage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"summary_text\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Return summary as string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14584\\2328961048.py\u001b[0m in \u001b[0;36marticleC\u001b[1;34m(pdfFile, version, start, end)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mtextCombined\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtextCombined\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Oops! The task failed as the PDF file is empty.\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Exception that handles empty files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextCombined\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Oops! The task failed as the PDF file has too little characters.\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Exception that handles files with too little characters for a summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Oops! The task failed as the PDF file is empty."
     ]
    }
   ],
   "source": [
    "# Summarize text\n",
    "text = sumArticle2(ArticleToSummarize)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'stanley', 2: 'vehicle', 3: 'figure', 4: '/h20850', 5: 'online'}\n"
     ]
    }
   ],
   "source": [
    "# Extract keywords and output them in dictionary format\n",
    "keywords = pdfKE(ArticleToSummarize)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dit document beschrijft de robot Stanley, die de 2005 DARPA Grand Challenge won. Stanley werd ontwikkeld met behulp van machine learning en probabilistische redenering om off-road terrein navigeren. Het doel van de Challenge was om een autonome robot te ontwikkelen die in staat is om ongehoren terrein van de weg over te brengen. Stanley maakt gebruik van een combinatie van traditionele statistische modellering en experimentele methoden om de relatieve snelheid en fout van elke etappe van de race te bepalen. Stanley slaagt erin om zowel de 2004 als 2005 wedstrijden te winnen. Dit document beschrijft verschillende benaderingen om de nauwkeurigheid van Stanley's navigatiesysteem te verbeteren. Ze onderzoeken twee verschillende methoden voor het voorspellen van obstakels op de weg en vinden dat beide zeer goed zijn in het detecteren en vermijden van deze hindernissen. Ze voeren een racesimulatie uit waarin ze de snelheid en richting van de robot over een periode van vierentwintig mijl voorspellen. Stanley overtreft de andere voertuigen in het eerste deel van het ras.\n"
     ]
    }
   ],
   "source": [
    "# Summarization translation\n",
    "translation = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-nl\") # Model used for the translation, imported from Huggingface (https://huggingface.co/Helsinki-NLP/opus-mt-en-nl)\n",
    "translatedText = translation(text)[0]['translation_text']\n",
    "print(translatedText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing lib: Kan opgegeven procedure niet vinden.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11644\\2432852475.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Cell only works in environment that works on pip. Evaluate isn't a library that has a conda recipe.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sacrebleu\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Model generated translation evaluated with DeepL generated translation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jklus\\anaconda3\\lib\\site-packages\\evaluate\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mevaluation_suite\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEvaluationSuite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m from .evaluator import (\n\u001b[0;32m     31\u001b[0m     \u001b[0mAutomaticSpeechRecognitionEvaluator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jklus\\anaconda3\\lib\\site-packages\\evaluate\\evaluation_suite\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDownloadMode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jklus\\anaconda3\\lib\\site-packages\\datasets\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplatform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpackaging\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jklus\\anaconda3\\lib\\site-packages\\pyarrow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0m_gc_enabled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_gc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misenabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[0m_gc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_gc_enabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0m_gc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing lib: Kan opgegeven procedure niet vinden."
     ]
    }
   ],
   "source": [
    "# Cell only works in environment that works on pip. Evaluate isn't a library that has a conda recipe.\n",
    "\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\") # Model generated translation evaluated with DeepL generated translation\n",
    "\n",
    "evaluationText = \"In dit artikel worden verschillende soorten modellen besproken die worden gebruikt om de ontwikkelingstijd en -kosten van software te voorspellen. Het meest gebruikte model is het Putnam SLIM model, dat gebaseerd is op een hellings-leercurve. De auteurs zijn echter van mening dat dit model niet betrouwbaar is bij het voorspellen van zeer vroege stadia van een project. Ze gebruiken een andere benadering, het 'Putnam-model', om toekomstige prestaties te voorspellen. In dit artikel stellen ze een nieuw type model voor dat toekomstige prestaties veel nauwkeuriger voorspelt dan het vorige Putnam-model. Dit nieuwe model kan op verschillende manieren worden geïmplementeerd, waaronder: het correleren van statistieken van real-time experimenten met machine learning, het gebruik van statistische methoden zoals rinterpreter en correlatieanalyse, modellering door directe observatie en het gebruik van geavanceerde statistische technieken zoals gewogen gemiddelden. De auteurs bespreken ook verschillende benaderingen voor het voorspellen van toekomstige prestaties van een bepaald soort product of functie. Als een bedrijf bijvoorbeeld een nieuw stuk machine zou introduceren, zou het in staat moeten zijn om het snel en op een hoog niveau te produceren over een lange periode.\"\n",
    "\n",
    "translatedText = \"Het meest gebruikte model is het Putnam SLIM model, dat gebaseerd is op een hellings-learning curve. Echter, de auteurs geloven dat het niet betrouwbaar is in het voorspellen van zeer vroege stadia van een project. Ze gebruiken een andere aanpak genaamd het 'Putnam model' om toekomstige prestaties te voorspellen. In dit document suggereren ze een nieuw type model dat toekomstige prestaties veel nauwkeuriger voorspelt dan het vorige Putnam model. Dit nieuwe model kan worden toegepast op verschillende manieren, waaronder: het correleren van statistieken van real-time experimenten met machine learning, gebruik makend van statistische methoden zoals rinterpreter en correlatieanalyse, modelleren door middel van directe observatie, en gebruik makend van geavanceerde statistische technieken zoals gewogen gemiddelde. De auteurs bespreken ook verschillende benaderingen voor het voorspellen van toekomstige prestaties van een bepaald soort product of functie. Bijvoorbeeld, als een bedrijf een nieuw stuk machines zou moeten kunnen introduceren, zou het snel en op een hoog niveau van tijd moeten produceren.\"\n",
    "\n",
    "predictions = [\n",
    "    translatedText\n",
    "]\n",
    "references = [\n",
    "    [\n",
    "        evaluationText\n",
    "    ]\n",
    "]\n",
    "metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "### ==============================\n",
    "#{'score': 53.86425158362457,\n",
    "#'counts': [149, 112, 95, 80],\n",
    "#'totals': [173, 172, 171, 170],\n",
    "#'precisions': [86.1271676300578,\n",
    "# 65.11627906976744,\n",
    "# 55.55555555555556,\n",
    "# 47.05882352941177],\n",
    "#'bp': 0.8704644809074915,\n",
    "#'sys_len': 173,\n",
    "#'ref_len': 197}\n",
    "### ==============================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
